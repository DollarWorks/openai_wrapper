# Token

## Goals
1. Calcuate how many tokens of a string. 

## Key Takeaways

* encoding
* models

Encoding:  `cl100k_base`
* models: 
    * `gpt-4`, 
    * `gpt-3.5-turbo`, 
    * `text-embedding-ada-002`

Encoding: `p50k_base`
* Models:
    * `Codex Models`
    * `text-davinci-002`,
    * `text-davinci-003`

Encoding: `r50k_base`, or `gpt2`
* Models:
    * `GPT-3 models like davinci`



## References

1. https://github.com/dqbd/tiktoken
2. https://platform.openai.com/tokenizer 


